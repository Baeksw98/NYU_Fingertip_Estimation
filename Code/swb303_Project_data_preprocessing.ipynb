{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00389509-1ace-4a39-ba85-9b975c1a16b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro to ML Capstone Project \n",
    "* Professor: Lerrel Pinto\n",
    "* Made by Sangwon Baek\n",
    "* December 7th 2022\n",
    "* Kaggle Site URL:\n",
    "https://www.kaggle.com/competitions/csci-ua-473-intro-to-machine-learning-fall22/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320f55b2-118e-47c5-b769-d67fd9e21b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ace22-77bf-47f8-ab6a-eea67051262e",
   "metadata": {},
   "source": [
    "### Preprocess my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3eae3f-167b-4166-8ae0-38389df74998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreLazyLoadDataset(Dataset):\n",
    "    def __init__(self, path, train=True, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        path = path + (\"train/\" if train else \"test/\")\n",
    "        \n",
    "        self.pathX = path+\"X/\"\n",
    "        self.pathY = path+\"Y/\"\n",
    "        \n",
    "        self.data = os.listdir(self.pathX)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        f = self.data[idx]\n",
    "        \n",
    "        #Read rgb images\n",
    "        img0 = cv2.imread(self.pathX + f + '/rgb/0.png')\n",
    "        img1 = cv2.imread(self.pathX + f + '/rgb/1.png')\n",
    "        img2 = cv2.imread(self.pathX + f + '/rgb/2.png')\n",
    "        \n",
    "        #Convert RGB & depth images to tensor\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)        \n",
    "        \n",
    "        #read depth images\n",
    "        depth = np.load(self.pathX + f + '/depth.npy')\n",
    "        depth = depth/1000\n",
    "        \n",
    "        #Perform transformation on Depth image\n",
    "        depth = cv2.normalize(depth, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)  \n",
    "               \n",
    "        #read field ID & Y\n",
    "        field_id = pkl.load(open(self.pathX + f + '/field_id.pkl', 'rb'))\n",
    "        Y = np.load(self.pathY + f + '.npy')\n",
    "        \n",
    "        return (img0, img1, img2, depth, field_id), Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecec6a5c-d8ad-48b7-b315-a4ad7a3f178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_first = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b3c4f-ebe7-4ae4-9634-6a870968773c",
   "metadata": {},
   "source": [
    "### Explore data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac18dae3-6192-478c-be6f-37f71a3c9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get mean and standard evication of RGB images and depth image for normalization value\n",
    "def get_mean_std(dataset):\n",
    "    meanRGB_img0 = [np.mean(image_0.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "    stdRGB_img0 = [np.std(image_0.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "    meanRGB_img1 = [np.mean(image_1.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "    stdRGB_img1 = [np.std(image_1.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "    meanRGB_img2 = [np.mean(image_2.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "    stdRGB_img2 = [np.std(image_2.numpy(), axis=(1,2)) for (image_0,image_1,image_2,image_depth,_),_ in dataset]\n",
    "\n",
    "    meanR_img0 = np.mean([m[0] for m in meanRGB_img0])\n",
    "    meanG_img0 = np.mean([m[1] for m in meanRGB_img0])\n",
    "    meanB_img0 = np.mean([m[2] for m in meanRGB_img0])\n",
    "    stdR_img0 = np.mean([s[0] for s in stdRGB_img0])\n",
    "    stdG_img0 = np.mean([s[1] for s in stdRGB_img0])\n",
    "    stdB_img0 = np.mean([s[2] for s in stdRGB_img0])\n",
    "    \n",
    "    print(\"Img_0 Mean: [{:.4F}, {:.4F}, {:.4F}]\".format(meanR_img0, meanG_img0, meanB_img0))\n",
    "    print(\"Img_0 STD: [{:.4F}, {:.4F}, {:.4F}]\".format(stdR_img0, stdG_img0, stdB_img0))\n",
    "\n",
    "    meanR_img1 = np.mean([m[0] for m in meanRGB_img1])\n",
    "    meanG_img1 = np.mean([m[1] for m in meanRGB_img1])\n",
    "    meanB_img1 = np.mean([m[2] for m in meanRGB_img1])\n",
    "    stdR_img1 = np.mean([s[0] for s in stdRGB_img1])\n",
    "    stdG_img1 = np.mean([s[1] for s in stdRGB_img1])\n",
    "    stdB_img1 = np.mean([s[2] for s in stdRGB_img1])\n",
    "    \n",
    "    print(\"Img_1 Mean: [{:.4F}, {:.4F}, {:.4F}]\".format(meanR_img1, meanG_img1, meanB_img1))\n",
    "    print(\"Img_1 STD: [{:.4F}, {:.4F}, {:.4F}]\".format(stdR_img1, stdG_img1, stdB_img1))\n",
    "\n",
    "    meanR_img2 = np.mean([m[0] for m in meanRGB_img2])\n",
    "    meanG_img2 = np.mean([m[1] for m in meanRGB_img2])\n",
    "    meanB_img2 = np.mean([m[2] for m in meanRGB_img2])\n",
    "    stdR_img2 = np.mean([s[0] for s in stdRGB_img2])\n",
    "    stdG_img2 = np.mean([s[1] for s in stdRGB_img2])\n",
    "    stdB_img2 = np.mean([s[2] for s in stdRGB_img2])\n",
    "    \n",
    "    print(\"Img_2 Mean: [{:.4F}, {:.4F}, {:.4F}]\".format(meanR_img2, meanG_img2, meanB_img2))\n",
    "    print(\"Img_2 STD: [{:.4F}, {:.4F}, {:.4F}]\".format(stdR_img2, stdG_img2, stdB_img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75daed85-b3ef-4cd7-a243-d0099e566985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LazyLoadDataset(Dataset):\n",
    "    def __init__(self, path, train=True, transform=None):\n",
    "        self.transform = transform\n",
    "        self.transform_0 = None\n",
    "        self.transform_1 = None\n",
    "        self.transform_2 = None\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            self.transform_0 = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(240),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize([0.4352, 0.4170, 0.3960], [0.1992, 0.1987, 0.2111])\n",
    "            ])\n",
    "            self.transform_1 = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(240),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize([0.5008, 0.4879, 0.4697], [0.2276, 0.2252, 0.2417])\n",
    "            ])\n",
    "            self.transform_2 = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(240),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.Normalize([0.5193, 0.4820, 0.4412], [0.2293, 0.2288, 0.2465])\n",
    "            ])\n",
    "        path = path + (\"train/\" if train else \"test/\")\n",
    "        \n",
    "        self.pathX = path+\"X/\"\n",
    "        self.pathY = path+\"Y/\"\n",
    "        \n",
    "        self.data = os.listdir(self.pathX)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        f = self.data[idx]\n",
    "        \n",
    "        #Read rgb images\n",
    "        img0 = cv2.imread(self.pathX + f + '/rgb/0.png')\n",
    "        img1 = cv2.imread(self.pathX + f + '/rgb/1.png')\n",
    "        img2 = cv2.imread(self.pathX + f + '/rgb/2.png')\n",
    "        \n",
    "        #read depth images\n",
    "        depth = np.load(self.pathX + f + '/depth.npy')        \n",
    "        depth = depth/1000\n",
    "        \n",
    "        #Convert RGB and depth images to tensor\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform_0(img0)\n",
    "            img1 = self.transform_1(img1)\n",
    "            img2 = self.transform_2(img2)\n",
    "        \n",
    "        #Perform transformation on Depth image\n",
    "        depth = cv2.normalize(depth, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)  \n",
    "            \n",
    "        #read field ID & Y\n",
    "        field_id = pkl.load(open(self.pathX + f + '/field_id.pkl', 'rb'))\n",
    "        Y = np.load(self.pathY + f + '.npy')\n",
    "        \n",
    "        return (img0, img1, img2, depth, field_id), Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9302fab7-3a34-4ed5-bc19-e22726075c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lazy Load the dataset\n",
    "preliminary_dataset = PreLazyLoadDataset('../lazydata/', transform=transform_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25a4cb8-cc42-423a-8255-78671ab1a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a,b,c,d,e), y = preliminary_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b49c9ef-e648-408d-88cb-f3cb89dfe3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img_0 Mean: [0.4352, 0.4170, 0.3960]\n",
      "Img_0 STD: [0.1992, 0.1987, 0.2111]\n",
      "Img_1 Mean: [0.5008, 0.4879, 0.4697]\n",
      "Img_1 STD: [0.2276, 0.2252, 0.2417]\n",
      "Img_2 Mean: [0.5193, 0.4820, 0.4412]\n",
      "Img_2 STD: [0.2293, 0.2288, 0.2465]\n"
     ]
    }
   ],
   "source": [
    "get_mean_std(preliminary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a1d1a0-570f-4a64-8faf-8c82a3fe8238",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LazyLoadDataset('../lazydata/', transform=transform_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99a7e63-fdd4-49b2-ad12-a6ae487c89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train/validation size (8:2)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "validation_size = len(dataset)-train_size\n",
    "\n",
    "#Randomly split dataset into train and validation dataset with specified size above\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "\n",
    "#Create train/validation dataloader with batch_size of 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed25f2be-f3e5-40a7-ba88-8f1a969e9721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2716 \n",
      "Train Loader size: 906\n",
      "Validation set size: 680 \n",
      "Validation Loader size: 227\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size: {} \\nTrain Loader size: {}\".format(len(train_dataset),len(train_dataloader)))\n",
    "print(\"Validation set size: {} \\nValidation Loader size: {}\".format(len(validation_dataset),len(validation_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c86a20-95ea-4451-97ba-22af68da852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "img0 shapetorch.Size([3, 3, 224, 224])\n",
      "img1 shapetorch.Size([3, 3, 224, 224])\n",
      "img2 shapetorch.Size([3, 3, 224, 224])\n",
      "depth shapetorch.Size([3, 3, 224, 224])\n",
      "field id ('3917', '779', '3283')\n",
      "labels size torch.Size([3, 12])\n"
     ]
    }
   ],
   "source": [
    "for i, ((img0, img1, img2, depth, field_id), labels) in enumerate(train_dataloader):\n",
    "    print(i)\n",
    "    # print(depth[0])\n",
    "    print(\"img0 shape{}\".format(img0.size()))\n",
    "    print(\"img1 shape{}\".format(img1.size()))\n",
    "    print(\"img2 shape{}\".format(img2.size()))\n",
    "    print(\"depth shape{}\".format(depth.shape))\n",
    "    print(\"field id {}\".format(field_id))\n",
    "    print(\"labels size {}\".format(labels.size()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd5052-d5f8-41c4-8e9c-cf6046d40f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
